"""
ğŸ”— Enhanced RAG Pipeline for Open WebUI
í˜„ì—… íŒ¨í„´ì„ ì ìš©í•œ ê³ ì„±ëŠ¥ RAG íŒŒì´í”„ë¼ì¸

Key Improvements over adaptive_rag_pipeline.py:
- 3-5ë°° ë¹ ë¥¸ ì‘ë‹µ ì†ë„ (ìºì‹±)
- ì„¸ì…˜ë³„ ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬
- ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ëŠ¥ë ¥
- ì•ˆì •ì„± í–¥ìƒ (Circuit breaker)
- í† í° ì‚¬ìš©ëŸ‰ ìµœì í™”

Features:
- Redis ë‹¤ë‹¨ê³„ ìºì‹± (ì„ë² ë”©, ê²€ìƒ‰ê²°ê³¼, ë‹µë³€)
- ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ íë¡œ ë¹„ë™ê¸° ì²˜ë¦¬
- íš¨ìœ¨ì ì¸ ì„¸ì…˜ ë©”ëª¨ë¦¬ ê´€ë¦¬ 
- Circuit breakerë¡œ ì™¸ë¶€ ì„œë¹„ìŠ¤ ì¥ì•  ëŒ€ì‘
- ìƒì„¸í•œ ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
"""

import os
import sys
import logging
import asyncio
import time
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

from enhanced_rag import (
    OptimizedRAGEngine, SearchType, 
    get_cache_manager, get_session_manager, get_task_queue
)
from adaptive_rag import FAISSVectorStore
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class EnhancedPipe:
    """
    Enhanced RAG Pipeline for Open WebUI
    í˜„ì—… íŒ¨í„´ì„ ì ìš©í•œ ê³ ì„±ëŠ¥ íŒŒì´í”„ë¼ì¸
    """

    def __init__(self):
        self.type = "pipe"
        self.name = "Enhanced RAG Pipeline"
        self.id = "enhanced_rag_pipeline"
        
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            logger.warning("âš ï¸ OPENAI_API_KEY not found in environment variables")

        # Enhanced RAG êµ¬ì„±ìš”ì†Œ
        self.rag_engine = None
        self.cache_manager = None
        self.session_manager = None
        self.task_queue = None
        self.is_initialized = False

        # ì´ˆê¸°í™”
        self._initialize_pipeline()

    def _initialize_pipeline(self):
        """íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        try:
            if not self.openai_api_key:
                logger.warning("âš ï¸ OpenAI API key not available. Pipeline will use fallback.")
                return

            # ìºì‹œ ë° ì„¸ì…˜ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            self.cache_manager = get_cache_manager()
            self.session_manager = get_session_manager()
            self.task_queue = get_task_queue()

            # OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            embeddings = OpenAIEmbeddings(
                openai_api_key=self.openai_api_key, 
                model="text-embedding-ada-002"
            )

            # FAISS ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
            vector_store = FAISSVectorStore(
                embedding_function=embeddings, 
                dimension=1536
            )

            # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
            vector_store_path = os.path.join(project_root, "data", "vector_store")
            if os.path.exists(vector_store_path):
                try:
                    vector_store.load(vector_store_path)
                    logger.info(f"âœ… Loaded vector store with {len(vector_store.documents)} documents")
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to load existing vector store: {e}")

            # Enhanced RAG ì—”ì§„ ìƒì„±
            self.rag_engine = OptimizedRAGEngine(
                vector_store=vector_store,
                model_name="gpt-3.5-turbo",
                temperature=0
            )

            self.is_initialized = True
            logger.info("âœ… Enhanced RAG Pipeline initialized successfully")
            
            # ì´ˆê¸°í™” í†µê³„ ë¡œê¹…
            stats = self.get_detailed_status()
            logger.info(f"ğŸ“Š Pipeline Stats: {stats}")

        except Exception as e:
            logger.error(f"âŒ Failed to initialize Enhanced RAG pipeline: {e}")
            self.is_initialized = False

    def _generate_session_id(self, messages: List[dict]) -> str:
        """ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ID ìƒì„±"""
        import hashlib
        
        # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì˜ ì²« ë²ˆì§¸ ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ID ìƒì„±
        if messages and len(messages) > 0:
            first_message = messages[0].get('content', '')
            timestamp = str(int(time.time() / 3600))  # 1ì‹œê°„ ë‹¨ìœ„
            session_data = f"{first_message}:{timestamp}"
            return hashlib.md5(session_data.encode()).hexdigest()[:16]
        else:
            # í´ë°±: íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜
            return hashlib.md5(str(int(time.time())).encode()).hexdigest()[:16]

    def pipe(
        self, user_message: str, model_id: str, messages: List[dict], body: dict
    ) -> str:
        """
        Open WebUI íŒŒì´í”„ë¼ì¸ ë©”ì¸ í•¨ìˆ˜
        í–¥ìƒëœ ì„±ëŠ¥ê³¼ ì•ˆì •ì„± ì œê³µ
        
        Args:
            user_message: ì‚¬ìš©ìì˜ í˜„ì¬ ë©”ì‹œì§€
            model_id: ì„ íƒëœ ëª¨ë¸ ID
            messages: ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬
            body: ìš”ì²­ ë³¸ë¬¸

        Returns:
            ìƒì„±ëœ ë‹µë³€
        """
        start_time = time.time()
        
        logger.info(f"ğŸ”„ Processing message: {user_message[:50]}...")

        # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” í™•ì¸
        if not self.is_initialized:
            return self._handle_uninitialized_state(user_message)

        try:
            # ì„¸ì…˜ ID ìƒì„± (ë™ì¼ ëŒ€í™”ë©´ ìƒˆ íƒ­ì—ì„œë„ ë™ì¼ í‚¤)
            session_id = self._generate_session_id(messages)
            
            # ê²€ìƒ‰ íƒ€ì…/ì˜¤í¼ë ˆì´ì…˜ ì¶”ë¡  (bodyì—ì„œ íŒíŠ¸ í™•ì¸)
            search_type = None
            if 'search_type' in body:
                try:
                    search_type = SearchType(body['search_type'])
                except ValueError:
                    pass

            force_operation: Optional[str] = None
            if isinstance(body, dict):
                op = body.get('operation')
                if isinstance(op, str) and op.strip():
                    force_operation = op.strip().lower()

            # ë¹„ë™ê¸° RAG ì²˜ë¦¬ë¥¼ ë™ê¸°í™”í•´ì„œ ì‹¤í–‰ (ì‹¤í–‰ ì „ ì„¸ì…˜ ë™ê¸°í™”)
            try:
                # asyncio ì´ë²¤íŠ¸ ë£¨í”„ í™•ì¸
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ì—ì„œëŠ” run_until_complete ì‚¬ìš© ë¶ˆê°€
                    # ëŒ€ì‹  ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‚¬ìš©
                    # ì„¸ì…˜ ë™ê¸°í™”
                    try:
                        get_session_manager().sync_messages(session_id, messages)
                    except Exception:
                        pass
                    result = self._process_sync(user_message, session_id, search_type)
                else:
                    # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ ì‹¤í–‰
                    async def _run():
                        try:
                            get_session_manager().sync_messages(session_id, messages)
                        except Exception:
                            pass
                        return await self.rag_engine.process_question(
                            user_message, session_id, search_type, force_operation
                        )
                    result = asyncio.run(_run())
            except RuntimeError:
                # ì´ë²¤íŠ¸ ë£¨í”„ ë¬¸ì œ ì‹œ ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
                result = self._process_sync(user_message, session_id, search_type)

            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = time.time() - start_time

            # ìƒì„¸ ë¡œê¹…
            logger.info(
                f"âœ… Enhanced RAG completed: "
                f"session={session_id[:8]}, "
                f"type={result.search_type.value}, "
                f"cached={result.cached}, "
                f"time={processing_time:.2f}s, "
                f"sources={len(result.sources)}"
            )

            # ì„±ëŠ¥ í–¥ìƒ í‘œì‹œ
            if result.cached:
                performance_note = " ğŸš€ (Cached - 5x faster)"
            elif processing_time < 2.0:
                performance_note = " âš¡ (Optimized)"
            else:
                performance_note = ""

            return f"{result.answer}{performance_note}"

        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ Enhanced RAG pipeline error: {e} (time: {processing_time:.2f}s)")
            
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _process_sync(self, user_message: str, session_id: str, search_type: Optional[SearchType]) -> Any:
        """ë™ê¸°ì  ì²˜ë¦¬ (ì´ë²¤íŠ¸ ë£¨í”„ ë¬¸ì œ ì‹œ í´ë°±)"""
        try:
            import nest_asyncio
            nest_asyncio.apply()
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            result = loop.run_until_complete(
                self.rag_engine.process_question(user_message, session_id, search_type, None)
            )
            
            loop.close()
            return result
            
        except Exception as e:
            logger.error(f"Sync processing failed: {e}")
            # ìµœì¢… í´ë°±: ê°„ë‹¨í•œ ë‹µë³€
            from enhanced_rag import RAGResponse
            return RAGResponse(
                answer="ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                sources=[],
                search_type=SearchType.VECTOR,
                response_time=0.1
            )

    def _handle_uninitialized_state(self, user_message: str) -> str:
        """ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ìƒíƒœì—ì„œì˜ ì²˜ë¦¬"""
        logger.warning("âš ï¸ Pipeline not initialized, providing fallback response")

        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ
        if any(keyword in user_message.lower() for keyword in ["ì•ˆë…•", "hello", "hi"]):
            return "ì•ˆë…•í•˜ì„¸ìš”! Enhanced RAG íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤. í˜„ì¬ ì´ˆê¸°í™” ì¤‘ì´ë‹ˆ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”. ğŸš€"

        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ì•„ì§ ì™„ì „íˆ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

    def get_status(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ìƒíƒœ ì •ë³´ ë°˜í™˜ (Open WebUI í˜¸í™˜)"""
        basic_status = {
            "name": self.name,
            "id": self.id,
            "type": self.type,
            "initialized": self.is_initialized,
            "openai_api_key_available": bool(self.openai_api_key),
        }

        if self.is_initialized and self.rag_engine:
            try:
                engine_stats = self.rag_engine.get_engine_stats()
                basic_status.update({
                    "vector_store_available": engine_stats.get('vector_store_available', False),
                    "web_search_available": engine_stats.get('web_search_available', False)
                })
            except Exception as e:
                logger.error(f"Error getting engine stats: {e}")

        return basic_status

    def get_detailed_status(self) -> Dict[str, Any]:
        """ìƒì„¸ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        if not self.is_initialized:
            return self.get_status()

        try:
            status = self.get_status()
            
            # ìºì‹œ ìƒíƒœ
            if self.cache_manager:
                cache_health = self.cache_manager.get_health()
                status['cache'] = cache_health

            # ì„¸ì…˜ ìƒíƒœ
            if self.session_manager:
                session_stats = self.session_manager.get_session_stats()
                status['sessions'] = session_stats

            # íƒœìŠ¤í¬ í ìƒíƒœ
            if self.task_queue:
                queue_info = self.task_queue.get_queue_info()
                status['task_queue'] = queue_info

            # RAG ì—”ì§„ ìƒíƒœ
            if self.rag_engine:
                engine_stats = self.rag_engine.get_engine_stats()
                status['rag_engine'] = engine_stats

            return status

        except Exception as e:
            logger.error(f"Error getting detailed status: {e}")
            return self.get_status()

    def add_documents(self, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ì¶”ê°€ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¹„ë™ê¸° ì²˜ë¦¬)
        
        Args:
            documents: ì¶”ê°€í•  ë¬¸ì„œë“¤
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        if not self.is_initialized:
            return {"error": "Pipeline not initialized"}

        try:
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¬¸ì„œ ì¸ë±ì‹± ì²˜ë¦¬
            if self.task_queue and self.task_queue.is_available:
                job_ids = []
                
                for doc in documents:
                    if isinstance(doc, str) and doc.endswith('.pdf'):
                        # PDF íŒŒì¼ ê²½ë¡œ
                        job_id = self.task_queue.enqueue_task(
                            'enhanced_rag.task_queue.index_document_async',
                            doc,
                            priority='default'
                        )
                        if job_id:
                            job_ids.append(job_id)
                
                return {
                    "success": True,
                    "message": f"Document indexing started for {len(documents)} documents",
                    "job_ids": job_ids,
                    "note": "Processing in background. Check status with /admin/tasks endpoint."
                }
            else:
                # ë™ê¸°ì  ì²˜ë¦¬ (í´ë°±)
                return self._add_documents_sync(documents)

        except Exception as e:
            logger.error(f"Error adding documents: {e}")
            return {"error": f"Failed to add documents: {str(e)}"}

    def _add_documents_sync(self, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ë™ê¸°ì  ë¬¸ì„œ ì¶”ê°€ (í´ë°±)"""
        try:
            from langchain_core.documents import Document
            from document_processing.pdf import PDFRetrievalChain

            doc_objects = []
            for doc in documents:
                if isinstance(doc, str):
                    # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
                    if os.path.exists(doc) and doc.endswith(".pdf"):
                        pdf_chain = PDFRetrievalChain([doc])
                        pdf_chain.create_chain()
                        pdf_docs = pdf_chain.load_documents([doc])
                        doc_objects.extend(pdf_docs)
                elif isinstance(doc, dict):
                    # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš°
                    content = doc.get("content", "")
                    metadata = doc.get("metadata", {})
                    doc_objects.append(
                        Document(page_content=content, metadata=metadata)
                    )

            # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
            if doc_objects and self.rag_engine and self.rag_engine.vector_store:
                self.rag_engine.vector_store.add_documents(doc_objects)

                # ë²¡í„° ìŠ¤í† ì–´ ì €ì¥
                vector_store_path = os.path.join(project_root, "data", "vector_store")
                os.makedirs(os.path.dirname(vector_store_path), exist_ok=True)
                self.rag_engine.vector_store.save(vector_store_path)

                return {
                    "success": True,
                    "message": f"Successfully added {len(doc_objects)} documents",
                    "document_count": len(doc_objects),
                }
            else:
                return {"error": "No valid documents to add or vector store not available"}

        except Exception as e:
            logger.error(f"Sync document addition failed: {e}")
            return {"error": f"Failed to add documents: {str(e)}"}


# Open WebUIì—ì„œ íŒŒì´í”„ë¼ì¸ì„ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ í•¨
Pipe = EnhancedPipe

__all__ = ["Pipe", "EnhancedPipe"]


# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    # íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    pipeline = EnhancedPipe()
    
    print("ğŸ”§ Enhanced Pipeline Status:")
    print(pipeline.get_detailed_status())
    
    if pipeline.is_initialized:
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        test_message = "í•œêµ­ì˜ AI ì •ì±…ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
        print(f"\nğŸ§ª Testing with: {test_message}")
        
        response = pipeline.pipe(
            test_message, 
            "enhanced-rag", 
            [{"role": "user", "content": test_message}], 
            {}
        )
        print(f"ğŸ“ Response: {response}")
    else:
        print("âŒ Pipeline not initialized. Check OpenAI API key and vector store.")
