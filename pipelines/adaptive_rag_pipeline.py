"""
ğŸ”— Open WebUI í†µí•© Adaptive RAG íŒŒì´í”„ë¼ì¸

Open WebUIì˜ Pipe ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬ LangGraph ê¸°ë°˜ Adaptive RAGë¥¼ í†µí•©í•©ë‹ˆë‹¤.

í•µì‹¬ ê¸°ëŠ¥:
- LangGraph ì›Œí¬í”Œë¡œìš°: Query Router â†’ Document Retriever â†’ Grader â†’ Generator
- FAISS ë²¡í„° ìŠ¤í† ì–´: 46ê°œ ë¬¸ì„œ ì„ë² ë”© ê²€ìƒ‰
- í•œêµ­ì–´ ì™„ë²½ ì§€ì›: ëª¨ë“  í”„ë¡¬í”„íŠ¸ì™€ ì‘ë‹µ í•œêµ­ì–´ ìµœì í™”
- ìê°€ ìˆ˜ì •: í’ˆì§ˆì´ ë‚®ì€ ë‹µë³€ ìë™ ì¬ìƒì„±
- í™˜ìƒ ë°©ì§€: ë¬¸ì„œ ê¸°ë°˜ ì‚¬ì‹¤ ê²€ì¦

Open WebUI Pipe ë©”ì„œë“œ:
- pipe(): ë©”ì¸ ì§ˆë¬¸-ë‹µë³€ ì²˜ë¦¬
- add_documents(): ìƒˆë¡œìš´ PDF ë¬¸ì„œ ì¶”ê°€
- get_status(): íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì •ë³´

ì‚¬ìš© ë°©ì‹:
1. OpenAI í˜¸í™˜ API ì„œë²„ë¡œ ì‹¤í–‰ (web_api_server.py)
2. Pipelines Plugin Frameworkë¡œ ì‹¤í–‰ (pipelines_server.py)
"""

import os
import sys
import logging
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

from adaptive_rag import AdaptiveRAGGraph, FAISSVectorStore
from langchain_openai import OpenAIEmbeddings
from rag.pdf import PDFRetrievalChain

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Pipe:
    """
    Open WebUIì—ì„œ ì¸ì‹í•˜ëŠ” ë©”ì¸ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤
    Adaptive RAG ê¸°ëŠ¥ì„ Open WebUIì™€ í†µí•©
    """

    def __init__(self):
        self.type = "pipe"
        self.name = "Adaptive RAG Pipeline"
        self.id = "adaptive_rag_pipeline"

        # í™˜ê²½ë³€ìˆ˜ í™•ì¸
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            logger.warning("OPENAI_API_KEY not found in environment variables")

        # Adaptive RAG êµ¬ì„±ìš”ì†Œ ì´ˆê¸°í™”
        self.vector_store = None
        self.rag_graph = None
        self.is_initialized = False

        # ì´ˆê¸°í™” ì‹œë„
        self._initialize_pipeline()

    def _initialize_pipeline(self):
        """íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        try:
            if not self.openai_api_key:
                logger.warning(
                    "OpenAI API key not available. Pipeline will use mock responses."
                )
                return

            # OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            embeddings = OpenAIEmbeddings(
                openai_api_key=self.openai_api_key, model="text-embedding-ada-002"
            )

            # FAISS ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
            self.vector_store = FAISSVectorStore(
                embedding_function=embeddings, dimension=1536
            )

            # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ê°€ ìˆë‹¤ë©´ ë¡œë“œ
            vector_store_path = os.path.join(project_root, "data", "vector_store")
            if os.path.exists(vector_store_path):
                try:
                    self.vector_store.load(vector_store_path)
                    logger.info("Loaded existing vector store")
                except Exception as e:
                    logger.warning(f"Failed to load existing vector store: {e}")

            # Adaptive RAG ê·¸ë˜í”„ ìƒì„±
            self.rag_graph = AdaptiveRAGGraph(
                vector_store=self.vector_store, model_name="gpt-3.5-turbo"
            )
            self.app = self.rag_graph.create_graph()

            self.is_initialized = True
            logger.info("Adaptive RAG Pipeline initialized successfully")

        except Exception as e:
            logger.error(f"Failed to initialize pipeline: {e}")
            self.is_initialized = False

    def pipe(
        self, user_message: str, model_id: str, messages: List[dict], body: dict
    ) -> str:
        """
        Open WebUIì—ì„œ í˜¸ì¶œí•˜ëŠ” ë©”ì¸ íŒŒì´í”„ë¼ì¸ ë©”ì„œë“œ

        Args:
            user_message: ì‚¬ìš©ìì˜ í˜„ì¬ ë©”ì‹œì§€
            model_id: ì„ íƒëœ ëª¨ë¸ ID
            messages: ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬
            body: ìš”ì²­ ë³¸ë¬¸

        Returns:
            ìƒì„±ëœ ë‹µë³€
        """
        logger.info(f"Processing message: {user_message}")

        # íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°
        if not self.is_initialized:
            return self._handle_uninitialized_state(user_message)

        try:
            # Adaptive RAG ê·¸ë˜í”„ ì‹¤í–‰
            result = self.rag_graph.run(user_message)

            # ìƒì„±ëœ ë‹µë³€ ë°˜í™˜
            generated_answer = result.get("generation", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # ë©”íƒ€ë°ì´í„° ë¡œê¹…
            documents = result.get("documents", [])
            logger.info(f"Generated answer using {len(documents)} documents")

            return generated_answer

        except Exception as e:
            logger.error(f"Error in pipeline execution: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _handle_uninitialized_state(self, user_message: str) -> str:
        """ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ìƒíƒœì—ì„œì˜ ì²˜ë¦¬"""
        logger.warning("Pipeline not initialized, providing fallback response")

        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ
        if any(keyword in user_message.lower() for keyword in ["ì•ˆë…•", "hello", "hi"]):
            return "ì•ˆë…•í•˜ì„¸ìš”! Adaptive RAG íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤. í˜„ì¬ ì´ˆê¸°í™” ì¤‘ì´ë‹ˆ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."

        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ì•„ì§ ì™„ì „íˆ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

    def add_documents(self, documents: List[dict]) -> Dict[str, Any]:
        """
        ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€

        Args:
            documents: ì¶”ê°€í•  ë¬¸ì„œë“¤ (path, content, metadata í¬í•¨)

        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        if not self.is_initialized:
            return {"error": "Pipeline not initialized"}

        try:
            from langchain_core.documents import Document

            # ë¬¸ì„œ ê°ì²´ ìƒì„±
            doc_objects = []
            for doc in documents:
                if isinstance(doc, str):
                    # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
                    if os.path.exists(doc) and doc.endswith(".pdf"):
                        pdf_chain = PDFRetrievalChain([doc])
                        pdf_chain.create_chain()  # ì²´ì¸ ìƒì„±
                        pdf_docs = pdf_chain.load_documents([doc])  # íŒŒë¼ë¯¸í„° ì „ë‹¬
                        doc_objects.extend(pdf_docs)
                elif isinstance(doc, dict):
                    # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš°
                    content = doc.get("content", "")
                    metadata = doc.get("metadata", {})
                    doc_objects.append(
                        Document(page_content=content, metadata=metadata)
                    )

            # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
            if doc_objects:
                self.vector_store.add_documents(doc_objects)

                # ë²¡í„° ìŠ¤í† ì–´ ì €ì¥
                vector_store_path = os.path.join(project_root, "data", "vector_store")
                os.makedirs(os.path.dirname(vector_store_path), exist_ok=True)
                self.vector_store.save(vector_store_path)

                return {
                    "success": True,
                    "message": f"Successfully added {len(doc_objects)} documents",
                    "document_count": len(doc_objects),
                }
            else:
                return {"error": "No valid documents to add"}

        except Exception as e:
            logger.error(f"Error adding documents: {e}")
            return {"error": f"Failed to add documents: {str(e)}"}

    def get_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        status = {
            "name": self.name,
            "id": self.id,
            "type": self.type,
            "initialized": self.is_initialized,
            "openai_api_key_available": bool(self.openai_api_key),
        }

        if self.vector_store:
            status.update(self.vector_store.get_stats())

        return status


# Open WebUIì—ì„œ íŒŒì´í”„ë¼ì¸ì„ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ í´ë˜ìŠ¤ë¥¼ ëª¨ë“ˆ ë ˆë²¨ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦
__all__ = ["Pipe"]

# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    # íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    pipeline = Pipe()
    print("Pipeline Status:", pipeline.get_status())

    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    test_message = "ì•ˆë…•í•˜ì„¸ìš”!"
    response = pipeline.pipe(test_message, "gpt-3.5-turbo", [], {})
    print(f"Test Response: {response}")
