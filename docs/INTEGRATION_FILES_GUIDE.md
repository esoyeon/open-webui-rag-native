# π”— Open WebUI β†” RAG μ‹μ¤ν… μ—°κ²°μ„ μ„ν• ν•µμ‹¬ νμΌ κ°€μ΄λ“

Adaptive RAG LangGraph λ² μ΄μ¤λΌμΈ λ¨λ“μ΄ μλ‹¤κ³  κ°€μ •ν•  λ•, Open WebUIμ™€ μ—°κ²°ν•κΈ° μ„ν•΄ μμ •/μƒμ„±ν•΄μ•Ό ν•  ν•µμ‹¬ νμΌλ“¤μ„ μ •λ¦¬ν•©λ‹λ‹¤.

## π“‹ **μμ •ν•΄μ•Ό ν•  ν•µμ‹¬ νμΌ λ©λ΅**

### **π”§ 1. API μ„λ²„ νμΌ (ν•„μ μƒμ„±)**
```python
# web_api_server.py - μƒλ΅ μƒμ„± ν•„μ”
```

**μ—­ν• **: OpenAI νΈν™ API μ„λ²„λ΅ Open WebUIμ™€ ν†µμ‹ 

**ν•µμ‹¬ κΈ°λ¥**:
- `/v1/models` μ—”λ“ν¬μΈνΈ (λ¨λΈ λ©λ΅)
- `/v1/chat/completions` μ—”λ“ν¬μΈνΈ (μ±„ν… μ™„λ£)
- CORS μ„¤μ •μΌλ΅ Open WebUI μ ‘κ·Ό ν—μ©

**ν•µμ‹¬ μ½”λ“ κµ¬μ΅°**:
```python
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pipelines.adaptive_rag_pipeline import Pipe

app = FastAPI(title="Adaptive RAG API")

# CORS μ„¤μ •
app.add_middleware(CORSMiddleware, allow_origins=["*"])

# νμ΄ν”„λΌμΈ μ΄κΈ°ν™”
pipeline = Pipe()

@app.get("/v1/models")
async def get_models():
    return {"data": [{"id": "adaptive-rag", "object": "model"}]}

@app.post("/v1/chat/completions")
async def chat_completion(request: ChatRequest):
    response = pipeline.pipe(
        user_message=request.messages[-1]["content"],
        model_id=request.model,
        messages=request.messages,
        body=request.dict()
    )
    return {"choices": [{"message": {"content": response}}]}
```

### **π”§ 2. νμ΄ν”„λΌμΈ μ–΄λ‘ν„° νμΌ (ν•„μ μƒμ„±)**
```python
# pipelines/adaptive_rag_pipeline.py - μƒλ΅ μƒμ„± ν•„μ”
```

**μ—­ν• **: LangGraph RAG μ‹μ¤ν…μ„ Open WebUI Pipe μΈν„°νμ΄μ¤λ΅ λν•‘

**ν•µμ‹¬ κΈ°λ¥**:
- `Pipe` ν΄λμ¤λ΅ Open WebUI μΈν„°νμ΄μ¤ κµ¬ν„
- λ²΅ν„° μ¤ν† μ–΄ μ΄κΈ°ν™” λ° λ΅λ“
- `pipe()` λ©”μ„λ“λ΅ μ§μμ‘λ‹µ μ²λ¦¬

**ν•µμ‹¬ μ½”λ“ κµ¬μ΅°**:
```python
class Pipe:
    def __init__(self):
        # λ²΅ν„° μ¤ν† μ–΄ μ΄κΈ°ν™”
        self.vector_store = FAISSVectorStore(embeddings)
        self.vector_store.load('data/vector_store')
        
        # LangGraph RAG μ‹μ¤ν… μ΄κΈ°ν™”
        self.rag_graph = AdaptiveRAGGraph(
            vector_store=self.vector_store,
            model_name="gpt-3.5-turbo"
        )
    
    def pipe(self, user_message, model_id, messages, body):
        # LangGraph μ‹¤ν–‰
        result = self.rag_graph.run({"question": user_message})
        return result["answer"]
    
    def get_status(self):
        return {"initialized": True, "total_documents": len(self.vector_store.documents)}
```

### **π”§ 3. ν™κ²½ μ„¤μ • νμΌ (ν•„μ μƒμ„±)**
```python
# .env - μƒλ΅ μƒμ„± ν•„μ”
```

**μ—­ν• **: API ν‚¤ λ° μ„¤μ • κ΄€λ¦¬

**ν•„μ ν‚¤**:
```bash
OPENAI_API_KEY=your_openai_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
```

### **π”§ 4. μμ΅΄μ„± κ΄€λ¦¬ νμΌ (μμ • ν•„μ”)**
```python
# pyproject.toml - μμ • ν•„μ”
```

**μ—­ν• **: Python ν¨ν‚¤μ§€ μμ΅΄μ„± κ΄€λ¦¬

**μ¶”κ°€ ν•„μ” ν¨ν‚¤μ§€**:
```toml
[tool.uv]
dependencies = [
    "fastapi>=0.104.0",
    "uvicorn[standard]>=0.24.0",
    "langchain>=0.1.0",
    "langgraph>=0.0.40",
    "faiss-cpu>=1.7.4",
    "openai>=1.0.0",
    "python-dotenv>=1.0.0",
    "pydantic>=2.0.0",
]
```

## π› οΈ **κµ¬μ²΄μ μΈ μμ • κ°€μ΄λ“**

### **1λ‹¨κ³„: API μ„λ²„ μƒμ„±**
1. `web_api_server.py` νμΌ μƒμ„±
2. FastAPI μ•± μ„¤μ •
3. OpenAI νΈν™ μ—”λ“ν¬μΈνΈ κµ¬ν„
4. CORS λ―Έλ“¤μ›¨μ–΄ μ¶”κ°€

### **2λ‹¨κ³„: νμ΄ν”„λΌμΈ μ–΄λ‘ν„° μƒμ„±**
1. `pipelines/` λ””λ ‰ν† λ¦¬ μƒμ„±
2. `adaptive_rag_pipeline.py` νμΌ μƒμ„±
3. `Pipe` ν΄λμ¤ κµ¬ν„
4. LangGraph RAG μ‹μ¤ν…κ³Ό μ—°κ²°

### **3λ‹¨κ³„: ν™κ²½ μ„¤μ •**
1. `.env` νμΌ μƒμ„±
2. API ν‚¤ μ„¤μ •
3. `pyproject.toml` μμ΅΄μ„± μ¶”κ°€

### **4λ‹¨κ³„: λ²΅ν„° μ¤ν† μ–΄ μ¤€λΉ„**
1. `data/vector_store/` λ””λ ‰ν† λ¦¬ μƒμ„±
2. FAISS μΈλ±μ¤ νμΌ μƒμ„±
3. λ¬Έμ„ μ„λ² λ”© μ™„λ£

## π― **ν•µμ‹¬ μ—°κ²° ν¬μΈνΈ**

### **Open WebUI β†’ API μ„λ²„**
```
Open WebUI (Frontend)
    β†“ HTTP Request
API Server (web_api_server.py)
    β†“ Function Call
Pipeline Adapter (adaptive_rag_pipeline.py)
    β†“ Method Call
LangGraph RAG System (adaptive_rag/)
```

### **λ°μ΄ν„° νλ¦„**
```
μ‚¬μ©μ μ§λ¬Έ β†’ Open WebUI β†’ API μ„λ²„ β†’ νμ΄ν”„λΌμΈ β†’ LangGraph β†’ λ²΅ν„° μ¤ν† μ–΄ β†’ λ‹µλ³€ μƒμ„±
```

## β… **κ²€μ¦ μ²΄ν¬λ¦¬μ¤νΈ**

- [ ] API μ„λ²„κ°€ `/v1/models` μ—”λ“ν¬μΈνΈ μ κ³µ
- [ ] API μ„λ²„κ°€ `/v1/chat/completions` μ—”λ“ν¬μΈνΈ μ κ³µ
- [ ] νμ΄ν”„λΌμΈμ΄ LangGraph RAG μ‹μ¤ν…κ³Ό μ—°κ²°λ¨
- [ ] λ²΅ν„° μ¤ν† μ–΄κ°€ μ •μƒ λ΅λ“λ¨
- [ ] ν™κ²½ λ³€μκ°€ μ¬λ°”λ¥΄κ² μ„¤μ •λ¨
- [ ] CORS μ„¤μ •μΌλ΅ Open WebUI μ ‘κ·Ό ν—μ©λ¨

## π€ **μ‹¤ν–‰ μμ„**

1. **ν™κ²½ μ„¤μ •**: `.env` νμΌ μƒμ„± λ° API ν‚¤ μ„¤μ •
2. **μμ΅΄μ„± μ„¤μΉ**: `uv pip install -e .`
3. **λ²΅ν„° μ¤ν† μ–΄ μ¤€λΉ„**: λ¬Έμ„ μΈλ±μ‹± μ™„λ£
4. **API μ„λ²„ μ‹¤ν–‰**: `python web_api_server.py`
5. **Open WebUI μ—°κ²°**: `http://localhost:8000/v1` λ°±μ—”λ“ μ„¤μ •

μ΄ κ°€μ΄λ“λ¥Ό λ”°λΌν•λ©΄ κΈ°μ΅΄ LangGraph RAG μ‹μ¤ν…μ„ Open WebUIμ™€ μ™„λ²½ν•κ² μ—°κ²°ν•  μ μμµλ‹λ‹¤!
